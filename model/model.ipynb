{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now work directly with the song genre year dataset after data aggregation and cleaning in dataset.ipynb.\n",
    "We have included the necessary files for running this notebook so that it can be run independently of data handling and doesn't need to be downloaded. (site might go down etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you run the notebook, create a virtual environment as mentioned in README.txt and make sure you are using that environment when running the cells.\n",
    "Install requirements.txt if not already done by running following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: asttokens==2.4.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.4.1)\n",
      "Requirement already satisfied: comm==0.2.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: debugpy==1.8.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.8.0)\n",
      "Requirement already satisfied: decorator==5.1.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (5.1.1)\n",
      "Requirement already satisfied: exceptiongroup==1.2.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: executing==2.0.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (2.0.1)\n",
      "Requirement already satisfied: Faker==20.1.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (20.1.0)\n",
      "Requirement already satisfied: h5py==3.10.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (3.10.0)\n",
      "Requirement already satisfied: ipykernel==6.27.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (6.27.1)\n",
      "Requirement already satisfied: ipython==8.18.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (8.18.1)\n",
      "Requirement already satisfied: jedi==0.19.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.19.1)\n",
      "Requirement already satisfied: joblib==1.3.2 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (1.3.2)\n",
      "Requirement already satisfied: jupyter_client==8.6.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (8.6.0)\n",
      "Requirement already satisfied: jupyter_core==5.5.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio==1.5.8 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (1.5.8)\n",
      "Requirement already satisfied: numpy==1.26.2 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (1.26.2)\n",
      "Requirement already satisfied: packaging==23.2 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (23.2)\n",
      "Requirement already satisfied: pandas==2.1.3 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 19)) (2.1.3)\n",
      "Requirement already satisfied: parso==0.8.3 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (0.8.3)\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 21)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs==4.0.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 22)) (4.0.0)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.41 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 23)) (3.0.41)\n",
      "Requirement already satisfied: psutil==5.9.6 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 24)) (5.9.6)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 25)) (0.7.0)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 26)) (0.2.2)\n",
      "Requirement already satisfied: Pygments==2.17.2 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 27)) (2.17.2)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2023.3.post1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 29)) (2023.3.post1)\n",
      "Requirement already satisfied: pyzmq==25.1.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 30)) (25.1.1)\n",
      "Requirement already satisfied: scikit-learn==1.3.2 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 31)) (1.3.2)\n",
      "Requirement already satisfied: scipy==1.11.4 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 32)) (1.11.4)\n",
      "Requirement already satisfied: six==1.16.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 33)) (1.16.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 34)) (0.6.3)\n",
      "Requirement already satisfied: threadpoolctl==3.2.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 35)) (3.2.0)\n",
      "Requirement already satisfied: tornado==6.4 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 36)) (6.4)\n",
      "Requirement already satisfied: tqdm==4.66.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 37)) (4.66.1)\n",
      "Requirement already satisfied: traitlets==5.14.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 38)) (5.14.0)\n",
      "Requirement already satisfied: tzdata==2023.3 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 39)) (2023.3)\n",
      "Requirement already satisfied: wcwidth==0.2.12 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 40)) (0.2.12)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JkO53EQ4x_Hg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "msd_df = pd.read_csv(\"song_genre_year.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ICSARzDaLrmy"
   },
   "outputs": [],
   "source": [
    "df = msd_df[[\"song_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAwv-z1AzVf-",
    "outputId": "bbdc69ad-2885-4458-d2e9-26faca78c0f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1                           0\n",
       "track_id                               0\n",
       "genre                                  0\n",
       "Unnamed: 0                             0\n",
       "analyzer_version                  152793\n",
       "artist_7digitalid                      0\n",
       "artist_familiarity                     0\n",
       "artist_hotttnesss                      0\n",
       "artist_id                              0\n",
       "artist_latitude                    94930\n",
       "artist_location                    55595\n",
       "artist_longitude                   94930\n",
       "artist_mbid                          719\n",
       "artist_name                            0\n",
       "artist_playmeid                        0\n",
       "idx_artist_terms                       0\n",
       "idx_similar_artists                    0\n",
       "release                                2\n",
       "release_7digitalid                     0\n",
       "song_hotttnesss                    39716\n",
       "song_id                                0\n",
       "title                                  0\n",
       "track_7digitalid                       0\n",
       "analysis_sample_rate                   0\n",
       "audio_md5                              0\n",
       "danceability                           0\n",
       "duration                               0\n",
       "end_of_fade_in                         0\n",
       "energy                                 0\n",
       "idx_bars_confidence                    0\n",
       "idx_bars_start                         0\n",
       "idx_beats_confidence                   0\n",
       "idx_beats_start                        0\n",
       "idx_sections_confidence                0\n",
       "idx_sections_start                     0\n",
       "idx_segments_confidence                0\n",
       "idx_segments_loudness_max              0\n",
       "idx_segments_loudness_max_time         0\n",
       "idx_segments_loudness_start            0\n",
       "idx_segments_pitches                   0\n",
       "idx_segments_start                     0\n",
       "idx_segments_timbre                    0\n",
       "idx_tatums_confidence                  0\n",
       "idx_tatums_start                       0\n",
       "key                                    0\n",
       "key_confidence                         0\n",
       "loudness                               0\n",
       "mode                                   0\n",
       "mode_confidence                        0\n",
       "start_of_fade_out                      0\n",
       "tempo                                  0\n",
       "time_signature                         0\n",
       "time_signature_confidence              0\n",
       "idx_artist_mbtags                      0\n",
       "year                                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msd_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wxlNN6Cem3qo",
    "outputId": "53f29532-9764-4921-ed0e-fe5daf842896"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1                           1\n",
       "track_id                               0\n",
       "genre                                  0\n",
       "Unnamed: 0                             0\n",
       "analyzer_version                       0\n",
       "artist_7digitalid                      0\n",
       "artist_familiarity                   108\n",
       "artist_hotttnesss                   1214\n",
       "artist_id                              0\n",
       "artist_latitude                        0\n",
       "artist_location                        0\n",
       "artist_longitude                       0\n",
       "artist_mbid                            0\n",
       "artist_name                            0\n",
       "artist_playmeid                        0\n",
       "idx_artist_terms                  152793\n",
       "idx_similar_artists               152793\n",
       "release                                0\n",
       "release_7digitalid                     0\n",
       "song_hotttnesss                     3957\n",
       "song_id                                0\n",
       "title                                  0\n",
       "track_7digitalid                       0\n",
       "analysis_sample_rate                   0\n",
       "audio_md5                              0\n",
       "danceability                      152793\n",
       "duration                               0\n",
       "end_of_fade_in                     44301\n",
       "energy                            152793\n",
       "idx_bars_confidence               152793\n",
       "idx_bars_start                    152793\n",
       "idx_beats_confidence              152793\n",
       "idx_beats_start                   152793\n",
       "idx_sections_confidence           152793\n",
       "idx_sections_start                152793\n",
       "idx_segments_confidence           152793\n",
       "idx_segments_loudness_max         152793\n",
       "idx_segments_loudness_max_time    152793\n",
       "idx_segments_loudness_start       152793\n",
       "idx_segments_pitches              152793\n",
       "idx_segments_start                152793\n",
       "idx_segments_timbre               152793\n",
       "idx_tatums_confidence             152793\n",
       "idx_tatums_start                  152793\n",
       "key                                18276\n",
       "key_confidence                      7967\n",
       "loudness                               0\n",
       "mode                               51456\n",
       "mode_confidence                     4072\n",
       "start_of_fade_out                      0\n",
       "tempo                                263\n",
       "time_signature                        54\n",
       "time_signature_confidence          29734\n",
       "idx_artist_mbtags                 152793\n",
       "year                                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msd_df.eq(0).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to lot of missing values or zeroes in a lot of features we narrow down to the following columns to be used for content based filtering further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "9dJUxgmNzMhW",
    "outputId": "567bc7aa-d7a2-4ac0-bd55-9eed770423b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>tempo</th>\n",
       "      <th>loudness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>152793.000000</td>\n",
       "      <td>152793.000000</td>\n",
       "      <td>152793.000000</td>\n",
       "      <td>152793.000000</td>\n",
       "      <td>152793.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1997.938721</td>\n",
       "      <td>5.324851</td>\n",
       "      <td>0.663231</td>\n",
       "      <td>125.436801</td>\n",
       "      <td>-9.291391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.204019</td>\n",
       "      <td>3.588301</td>\n",
       "      <td>0.472607</td>\n",
       "      <td>34.157529</td>\n",
       "      <td>4.626484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1922.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-55.751000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1994.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.423000</td>\n",
       "      <td>-11.658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2002.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>122.987000</td>\n",
       "      <td>-8.297000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2006.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>146.523000</td>\n",
       "      <td>-5.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>269.510000</td>\n",
       "      <td>4.150000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                year            key           mode          tempo  \\\n",
       "count  152793.000000  152793.000000  152793.000000  152793.000000   \n",
       "mean     1997.938721       5.324851       0.663231     125.436801   \n",
       "std        11.204019       3.588301       0.472607      34.157529   \n",
       "min      1922.000000       0.000000       0.000000       0.000000   \n",
       "25%      1994.000000       2.000000       0.000000      99.423000   \n",
       "50%      2002.000000       5.000000       1.000000     122.987000   \n",
       "75%      2006.000000       9.000000       1.000000     146.523000   \n",
       "max      2010.000000      11.000000       1.000000     269.510000   \n",
       "\n",
       "            loudness  \n",
       "count  152793.000000  \n",
       "mean       -9.291391  \n",
       "std         4.626484  \n",
       "min       -55.751000  \n",
       "25%       -11.658000  \n",
       "50%        -8.297000  \n",
       "75%        -5.930000  \n",
       "max         4.150000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msd_df[[\"song_id\", \"genre\", \"year\", \"key\", \"mode\", \"tempo\", \"loudness\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be dealing with a subset of the user song interactions dataset. It consists of user_id, song_id, listen_count triplets i.e. what song a user listened to and how many times. \n",
    "\n",
    "There are 48 Million user song interactions! Training on the whole is out of the scope of this project. Since the crux of our algorithm relies on creating a user-item interaction matrix it takes up huge amounts of RAM.\n",
    "\n",
    "To just train 500K user song interactions we required 128 GB RAM on 1 CPU node on a PACE cluster provided by Georgia Tech.\n",
    "\n",
    "The user_play_counts.csv is a subset of the train_triplets.txt which we downloaded in dataset.ipynb and contains 500k rows out of 48M.\n",
    "\n",
    "To successfully run the demo on your system or colab, we recommend keeping nrows=10_000 to 100_000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rWcIItcPSPTb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>listen_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAKIMP12A8C130995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAPDEY12A81C210A9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBBMDR12A8C13253B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBFNSP12AF72A0E22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBFOVM12A58A7D494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>8caf9a87e266a22298bd977a63489d008af241c5</td>\n",
       "      <td>SOETKSY12A8C13C666</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>8caf9a87e266a22298bd977a63489d008af241c5</td>\n",
       "      <td>SOFPXJZ12A6D4F6444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>8caf9a87e266a22298bd977a63489d008af241c5</td>\n",
       "      <td>SOFRCGW12A81C21EA6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>8caf9a87e266a22298bd977a63489d008af241c5</td>\n",
       "      <td>SOFUVPZ12A6D4FCEA3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>8caf9a87e266a22298bd977a63489d008af241c5</td>\n",
       "      <td>SOGKCNH12A8C139F79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       user_id             song_id  \\\n",
       "0     b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995   \n",
       "1     b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAPDEY12A81C210A9   \n",
       "2     b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B   \n",
       "3     b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFNSP12AF72A0E22   \n",
       "4     b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFOVM12A58A7D494   \n",
       "...                                        ...                 ...   \n",
       "9995  8caf9a87e266a22298bd977a63489d008af241c5  SOETKSY12A8C13C666   \n",
       "9996  8caf9a87e266a22298bd977a63489d008af241c5  SOFPXJZ12A6D4F6444   \n",
       "9997  8caf9a87e266a22298bd977a63489d008af241c5  SOFRCGW12A81C21EA6   \n",
       "9998  8caf9a87e266a22298bd977a63489d008af241c5  SOFUVPZ12A6D4FCEA3   \n",
       "9999  8caf9a87e266a22298bd977a63489d008af241c5  SOGKCNH12A8C139F79   \n",
       "\n",
       "      listen_count  \n",
       "0                1  \n",
       "1                1  \n",
       "2                2  \n",
       "3                1  \n",
       "4                1  \n",
       "...            ...  \n",
       "9995            12  \n",
       "9996             1  \n",
       "9997             3  \n",
       "9998             2  \n",
       "9999             1  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_play_counts_df = pd.read_csv(\"user_play_counts.csv\", index_col=0, nrows=10_000)\n",
    "user_play_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working on a subset of the song metadata after filtering out songs, we need to make sure the user song interactions have those song_ids available. Hence we perform an inner join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RTJhRyrRSPTc"
   },
   "outputs": [],
   "source": [
    "df = user_play_counts_df.merge(df, on=\"song_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following algorithm is a modified version for the million song dataset from the open source code available for the research paper: https://arxiv.org/abs/1905.03375. This algorithm applies only collaborative filtering as explained in the report. We will be training and evaluating this model and treating it as the baseline model to compare performance against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ILTV_kQfmziM"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "\n",
    "class EASE:\n",
    "    def __init__(self):\n",
    "        self.user_enc = LabelEncoder()\n",
    "        self.item_enc = LabelEncoder()\n",
    "\n",
    "    def _get_users_and_items(self, df):\n",
    "        users = self.user_enc.fit_transform(df.loc[:, \"user_id\"])\n",
    "        items = self.item_enc.fit_transform(df.loc[:, \"song_id\"])\n",
    "        return users, items\n",
    "\n",
    "    def fit(self, df, lambda_: float = 0.5, implicit=True):\n",
    "        \"\"\"\n",
    "        df: pandas.DataFrame with columns user_id, song_id, and (listen_count)\n",
    "        lambda_: l2-regularization term\n",
    "        implicit: if True, listen_count is ignored and taken as 1, else normalized listen_count is used\n",
    "        \"\"\"\n",
    "        users, items = self._get_users_and_items(df)\n",
    "        values = (\n",
    "            np.ones(df.shape[0])\n",
    "            if implicit\n",
    "            else df[\"listen_count\"].to_numpy() / df[\"listen_count\"].max()\n",
    "        )\n",
    "\n",
    "        X = csr_matrix((values, (users, items)))\n",
    "        self.X = X\n",
    "\n",
    "        G = X.T.dot(X).toarray()\n",
    "        diagIndices = np.diag_indices(G.shape[0])\n",
    "        G[diagIndices] += lambda_\n",
    "        P = np.linalg.inv(G)\n",
    "        B = P / (-np.diag(P))\n",
    "        B[diagIndices] = 0\n",
    "\n",
    "        self.B = B\n",
    "        self.pred = X.dot(B)\n",
    "\n",
    "    def predict(self, train, users, items, k):\n",
    "        items = self.item_enc.transform(items)\n",
    "        dd = train.loc[train.user_id.isin(users)]\n",
    "        dd[\"ci\"] = self.item_enc.transform(dd.song_id)\n",
    "        dd[\"cu\"] = self.user_enc.transform(dd.user_id)\n",
    "        g = dd.groupby(\"cu\")\n",
    "        with Pool(cpu_count()) as p:\n",
    "            user_preds = p.starmap(\n",
    "                self.predict_for_user,\n",
    "                [(user, group, self.pred[user, :], items, k) for user, group in g],\n",
    "            )\n",
    "        df = pd.concat(user_preds)\n",
    "        df[\"song_id\"] = self.item_enc.inverse_transform(df[\"song_id\"])\n",
    "        df[\"user_id\"] = self.user_enc.inverse_transform(df[\"user_id\"])\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def predict_for_user(user, group, pred, items, k):\n",
    "        watched = set(group[\"ci\"])\n",
    "        candidates = [item for item in items if item not in watched]\n",
    "        pred = np.take(pred, candidates)\n",
    "\n",
    "        res = np.argpartition(pred, -k)[-k:]\n",
    "        r = pd.DataFrame(\n",
    "            {\n",
    "                \"user_id\": [user] * len(res),\n",
    "                \"song_id\": np.take(candidates, res),\n",
    "                \"score\": np.take(pred, res),\n",
    "            }\n",
    "        ).sort_values(\"score\", ascending=False)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, following model is the novel hybrid filtering approach we introduce to EASE and call it EASEwithFeatures. While training the model (fit) we separately calculate cosine similarity for the song_features. While predicting the score for recommendations for a user we use the combined score of collaborative filtering and weighted score of the features of the song and this is how we incorporate a hybrid filtering recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ubaAtlvV4Xty"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "\n",
    "class EASEwithFeatures:\n",
    "    def __init__(self):\n",
    "        self.user_enc = LabelEncoder()\n",
    "        self.item_enc = LabelEncoder()\n",
    "        self.song_features = None\n",
    "\n",
    "    def _get_users_and_items(self, df):\n",
    "        users = self.user_enc.fit_transform(df.loc[:, \"user_id\"])\n",
    "        items = self.item_enc.fit_transform(df.loc[:, \"song_id\"])\n",
    "        return users, items\n",
    "\n",
    "    def fit(self, df, lambda_: float = 0.5, implicit=True, song_features=None):\n",
    "        \"\"\"\n",
    "        df: pandas.DataFrame with columns user_id, song_id, and (listen_count)\n",
    "        lambda_: l2-regularization term\n",
    "        implicit: if True, listen_count is ignored and taken as 1, else normalized listen_count is used\n",
    "        \"\"\"\n",
    "        users, items = self._get_users_and_items(df)\n",
    "        values = (\n",
    "            np.ones(df.shape[0])\n",
    "            if implicit\n",
    "            else df[\"listen_count\"].to_numpy() / df[\"listen_count\"].max()\n",
    "        )\n",
    "\n",
    "        X = csr_matrix((values, (users, items)))\n",
    "        self.X = X\n",
    "        self.song_features = csr_matrix(song_features.drop(\"song_id\", axis=1))\n",
    "\n",
    "        G = X.T.dot(X).toarray()\n",
    "        diagIndices = np.diag_indices(G.shape[0])\n",
    "        G[diagIndices] += lambda_\n",
    "        P = np.linalg.inv(G)\n",
    "        B = P / (-np.diag(P))\n",
    "        B[diagIndices] = 0\n",
    "\n",
    "        self.B = B\n",
    "        self.pred = X.dot(B)\n",
    "\n",
    "    def predict(self, train, users, items, k):\n",
    "        items = self.item_enc.transform(items)\n",
    "        dd = train.loc[train.user_id.isin(users)]\n",
    "        dd.loc[:, \"ci\"] = self.item_enc.transform(dd[\"song_id\"])\n",
    "        dd.loc[:, \"cu\"] = self.user_enc.transform(dd[\"user_id\"])\n",
    "        g = dd.groupby(\"cu\")\n",
    "        with Pool(cpu_count()) as p:\n",
    "            user_preds = p.starmap(\n",
    "                self.predict_for_user,\n",
    "                [\n",
    "                    (user, group, self.pred[user, :], items, k, self.song_features)\n",
    "                    for user, group in g\n",
    "                ],\n",
    "            )\n",
    "        df = pd.concat(user_preds)\n",
    "        df[\"song_id\"] = self.item_enc.inverse_transform(df[\"song_id\"])\n",
    "        df[\"user_id\"] = self.user_enc.inverse_transform(df[\"user_id\"])\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def predict_for_user(user, group, pred, items, k, song_features):\n",
    "        watched = set(group[\"ci\"])\n",
    "        candidates = [item for item in items if item not in watched]\n",
    "        pred = np.take(pred, candidates)\n",
    "\n",
    "        song_features_indices = np.array(candidates)\n",
    "        song_features_values = song_features[song_features_indices, :]\n",
    "        combined_scores = pred\n",
    "\n",
    "        num_features = song_features_values.shape[1]\n",
    "        for i in range(num_features):\n",
    "            feature_scores = song_features_values[:, i] * 0.001\n",
    "            combined_scores += feature_scores.toarray().ravel()\n",
    "\n",
    "        res = np.argpartition(combined_scores, -k)[-k:]\n",
    "        r = pd.DataFrame(\n",
    "            {\n",
    "                \"user_id\": [user] * len(res),\n",
    "                \"song_id\": np.take(candidates, res),\n",
    "                \"score\": combined_scores[res],\n",
    "            }\n",
    "        ).sort_values(\"score\", ascending=False)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select the features from song metadata and apply necessary transformations before feeding into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "18Y9J2C516Kt",
    "outputId": "a1e94ef3-a498-4e9d-ac5c-39e58ee5407a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                    song_id     genre  song_hotttnesss      year       key  \\\n",
       "0       SOBLFFE12AF72AA5BA  0.928571         0.733372  0.988636  0.090909   \n",
       "1       SOCSNVI12A8C13ECC2  0.928571         0.375984  0.545455  0.636364   \n",
       "2       SONHOTT12A8C13493C  0.928571         0.526079  0.681818  0.000000   \n",
       "3       SOIGICF12A8C141BC5  0.142857         0.468998  0.931818  1.000000   \n",
       "4       SOEPPTV12AC4689D86  0.571429         0.526079  0.943182  0.454545   \n",
       "...                    ...       ...              ...       ...       ...   \n",
       "152788  SOFBODT12AB0180C40  0.928571         0.253835  0.840909  0.909091   \n",
       "152789  SOISCAF12A8C142C8C  0.928571         0.360371  0.943182  0.909091   \n",
       "152790  SOULKJA12A8C140620  0.928571         0.686652  0.920455  0.181818   \n",
       "152791  SOSULQJ12A8C144B79  0.214286         0.530026  0.556818  0.636364   \n",
       "152792  SOZPUEF12AF72A9F2A  0.142857         0.392009  0.897727  0.090909   \n",
       "\n",
       "        mode     tempo  loudness  \n",
       "0          1  0.370836  0.851104  \n",
       "1          1  0.507469  0.709938  \n",
       "2          1  0.442629  0.780254  \n",
       "3          0  0.341164  0.761406  \n",
       "4          1  0.357248  0.559072  \n",
       "...      ...       ...       ...  \n",
       "152788     1  0.405399  0.667785  \n",
       "152789     1  0.573025  0.718385  \n",
       "152790     1  0.299276  0.686032  \n",
       "152791     1  0.338140  0.689404  \n",
       "152792     1  0.666706  0.772708  \n",
       "\n",
       "[152793 rows x 8 columns]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "song_features = msd_df[\n",
    "    [\"song_id\", \"genre\", \"song_hotttnesss\", \"year\", \"key\", \"mode\", \"tempo\", \"loudness\"]\n",
    "]\n",
    "mean_hotttnesss = song_features[\"song_hotttnesss\"].mean()\n",
    "song_features.loc[:, \"song_hotttnesss\"].fillna(mean_hotttnesss, inplace=True)\n",
    "\n",
    "# numerically encode genre\n",
    "label_encoder = LabelEncoder()\n",
    "song_features[\"genre\"] = label_encoder.fit_transform(song_features[\"genre\"])\n",
    "\n",
    "# normalize numerical columns\n",
    "scaler = MinMaxScaler()\n",
    "song_features[[\"song_hotttnesss\"]] = scaler.fit_transform(\n",
    "    song_features[[\"song_hotttnesss\"]]\n",
    ")\n",
    "song_features[[\"genre\"]] = scaler.fit_transform(song_features[[\"genre\"]])\n",
    "song_features[[\"year\"]] = scaler.fit_transform(song_features[[\"year\"]])\n",
    "song_features[[\"key\"]] = scaler.fit_transform(song_features[[\"key\"]])\n",
    "song_features[[\"tempo\"]] = scaler.fit_transform(song_features[[\"tempo\"]])\n",
    "song_features[[\"loudness\"]] = scaler.fit_transform(song_features[[\"loudness\"]])\n",
    "\n",
    "song_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now evaluate our models.\n",
    "We will be calculating hit rate, arhr (average reciprocal hit rate), novelty, precision and recall and comparing EASE and EASEwithFeatures. All of these have been explained in brief in final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting EASE Model\n",
      "Evalution score for EASE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  36%|███▋      | 53/146 [00:16<00:25,  3.65it/s]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "all_song_ids = train_df[\"song_id\"].unique()\n",
    "\n",
    "\n",
    "def evaluate_model(ease_model):\n",
    "    hits = 0\n",
    "    total_users = 0\n",
    "    arhr_sum = 0\n",
    "    novelty_sum = 0\n",
    "    novelty_count = 0\n",
    "    total_correct_recommended = 0\n",
    "    total_recommended = 0\n",
    "    total_relevant = 0\n",
    "    k = 10\n",
    "\n",
    "    grouped_test_df = test_df.groupby(\"user_id\")\n",
    "\n",
    "    for user_id, user_data in tqdm(grouped_test_df, desc=\"Evaluating Model\"):\n",
    "        actual_interactions = set(user_data[\"song_id\"])\n",
    "\n",
    "        try:\n",
    "            recommendations = ease_model.predict(train_df, [user_id], all_song_ids, k)\n",
    "            recommended_songs = set(recommendations[\"song_id\"])\n",
    "\n",
    "            hits += len(actual_interactions & recommended_songs) > 0\n",
    "\n",
    "            intersection = list(actual_interactions & recommended_songs)\n",
    "            if intersection:\n",
    "                intersection_rank = recommendations.index[\n",
    "                    recommendations[\"song_id\"] == intersection[0]\n",
    "                ][0]\n",
    "                reciprocal_rank = 1 / (intersection_rank + 1)\n",
    "                arhr_sum += reciprocal_rank\n",
    "\n",
    "            song_user_counts = train_df[train_df[\"song_id\"].isin(recommended_songs)][\n",
    "                \"user_id\"\n",
    "            ].nunique()\n",
    "            novelty_sum += song_user_counts\n",
    "            novelty_count += len(recommended_songs)\n",
    "\n",
    "            total_recommended += len(recommended_songs)\n",
    "            total_relevant += len(actual_interactions)\n",
    "            total_correct_recommended += len(actual_interactions & recommended_songs)\n",
    "\n",
    "            total_users += 1\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    hit_rate = hits / total_users if total_users > 0 else 0.0\n",
    "    arhr = arhr_sum / total_users if total_users > 0 else 0\n",
    "    novelty = novelty_sum / novelty_count if novelty_count > 0 else 0\n",
    "    precision = (\n",
    "        total_correct_recommended / total_recommended if total_recommended > 0 else 0.0\n",
    "    )\n",
    "    recall = total_correct_recommended / total_relevant if total_relevant > 0 else 0.0\n",
    "\n",
    "    print(\"Hit Rate:\", hit_rate)\n",
    "    print(\"ARHR:\", arhr)\n",
    "    print(\"Novelty:\", novelty)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "\n",
    "ease_model = EASE()\n",
    "print(\"Fitting EASE Model\")\n",
    "ease_model.fit(train_df, lambda_=0.5, implicit=True)\n",
    "print(\"Evalution score for EASE\")\n",
    "evaluate_model(ease_model)\n",
    "\n",
    "ease_model_with_features = EASEwithFeatures()\n",
    "print(\"Fitting EASE with Features Model\")\n",
    "ease_model_with_features.fit(\n",
    "    train_df, lambda_=0.5, implicit=True, song_features=song_features\n",
    ")\n",
    "print(\"Evalution score for EASE with features\")\n",
    "evaluate_model(ease_model_with_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will be training on the whole dataset and generate recommendations for all users for the interactive UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWjWdC1wNNLU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:58<00:00,  2.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAOAHZ12A8C13AAF1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SORKFWO12A8C138D83</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOHSOEO12A8C1314F9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOUKJBT12A6701C4D6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOGKBUP12A8AE46251</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b4adf5ac8bcba59011df7be840dda1134a47cc30</td>\n",
       "      <td>SOHWTCP12A3F1EA9EB</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b4adf5ac8bcba59011df7be840dda1134a47cc30</td>\n",
       "      <td>SOMXBSN12A6310E0DC</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b4adf5ac8bcba59011df7be840dda1134a47cc30</td>\n",
       "      <td>SORWGRQ12A8C13FFA1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b4adf5ac8bcba59011df7be840dda1134a47cc30</td>\n",
       "      <td>SODZXQS12A6D4F6C0E</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b4adf5ac8bcba59011df7be840dda1134a47cc30</td>\n",
       "      <td>SOFLNJE12A6D4F84FB</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1710 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     user_id             song_id  rank\n",
       "7   b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAOAHZ12A8C13AAF1     1\n",
       "8   b80344d063b5ccb3212f76538f3d9e43d87dca9e  SORKFWO12A8C138D83     2\n",
       "9   b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOHSOEO12A8C1314F9     3\n",
       "6   b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOUKJBT12A6701C4D6     4\n",
       "2   b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOGKBUP12A8AE46251     5\n",
       "..                                       ...                 ...   ...\n",
       "4   b4adf5ac8bcba59011df7be840dda1134a47cc30  SOHWTCP12A3F1EA9EB     6\n",
       "1   b4adf5ac8bcba59011df7be840dda1134a47cc30  SOMXBSN12A6310E0DC     7\n",
       "3   b4adf5ac8bcba59011df7be840dda1134a47cc30  SORWGRQ12A8C13FFA1     8\n",
       "2   b4adf5ac8bcba59011df7be840dda1134a47cc30  SODZXQS12A6D4F6C0E     9\n",
       "0   b4adf5ac8bcba59011df7be840dda1134a47cc30  SOFLNJE12A6D4F84FB    10\n",
       "\n",
       "[1710 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EASEwithFeatures()\n",
    "model.fit(df, lambda_=0.5, implicit=True, song_features=song_features)\n",
    "\n",
    "\n",
    "def generate_recommendations_for_all_users(model, users, all_items, k):\n",
    "    all_recommendations = []\n",
    "    for user in tqdm(users):\n",
    "        recommendations = model.predict(df, [user], all_items, k)\n",
    "        recommendations[\"rank\"] = recommendations.groupby(\"user_id\").cumcount() + 1\n",
    "        all_recommendations.append(recommendations)\n",
    "\n",
    "    all_recommendations = pd.concat(all_recommendations)\n",
    "    return all_recommendations\n",
    "\n",
    "\n",
    "all_song_ids = df[\"song_id\"].unique()\n",
    "all_users = df[\"user_id\"].unique()\n",
    "\n",
    "all_user_recommendations = generate_recommendations_for_all_users(\n",
    "    model, all_users, all_song_ids, k=10\n",
    ")\n",
    "all_user_recommendations[[\"user_id\", \"song_id\", \"rank\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the force directed graph on UI we also need to show song similarities after recommending top k recommendations. Hence we use normal cosine_similarity (content based filtering only) to satisfy this feature. \n",
    "\n",
    "Note: Doing this only for 100 songs for demo purposes. If you run for whole dataset there will be 1.5 million rows generated (took around an hour on PACE with 1 Node 8 cores 24 GB RAM which we have employed in our UI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bhFGC6kZywc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recommend songs using song similarity:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recommend songs using song similarity: 100%|██████████| 100/100 [00:08<00:00, 11.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_song_id</th>\n",
       "      <th>target_song_id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOBLFFE12AF72AA5BA</td>\n",
       "      <td>SOWFJJN12A6D4FC7B6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOBLFFE12AF72AA5BA</td>\n",
       "      <td>SOUHCLN12A8AE46CD9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOBLFFE12AF72AA5BA</td>\n",
       "      <td>SOSVMUX12AB0181BC9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOBLFFE12AF72AA5BA</td>\n",
       "      <td>SOKGYUR12A6D4F7D55</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOBLFFE12AF72AA5BA</td>\n",
       "      <td>SOZWDIG12A8C139830</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>SOQAHLN12A8C13F853</td>\n",
       "      <td>SOTSRUQ12A81C22359</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>SOQAHLN12A8C13F853</td>\n",
       "      <td>SOKMUSD12A6D4F528D</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>SOQAHLN12A8C13F853</td>\n",
       "      <td>SOAAMAA12A58A7F88A</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>SOQAHLN12A8C13F853</td>\n",
       "      <td>SONPTBS12AB018E4B9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>SOQAHLN12A8C13F853</td>\n",
       "      <td>SOLWLXM12A8C1323AD</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         source_song_id      target_song_id  rank\n",
       "0    SOBLFFE12AF72AA5BA  SOWFJJN12A6D4FC7B6     1\n",
       "1    SOBLFFE12AF72AA5BA  SOUHCLN12A8AE46CD9     2\n",
       "2    SOBLFFE12AF72AA5BA  SOSVMUX12AB0181BC9     3\n",
       "3    SOBLFFE12AF72AA5BA  SOKGYUR12A6D4F7D55     4\n",
       "4    SOBLFFE12AF72AA5BA  SOZWDIG12A8C139830     5\n",
       "..                  ...                 ...   ...\n",
       "895  SOQAHLN12A8C13F853  SOTSRUQ12A81C22359     5\n",
       "896  SOQAHLN12A8C13F853  SOKMUSD12A6D4F528D     6\n",
       "897  SOQAHLN12A8C13F853  SOAAMAA12A58A7F88A     7\n",
       "898  SOQAHLN12A8C13F853  SONPTBS12AB018E4B9     8\n",
       "899  SOQAHLN12A8C13F853  SOLWLXM12A8C1323AD     9\n",
       "\n",
       "[900 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "song_ids = msd_df[\"song_id\"][:100]\n",
    "\n",
    "\n",
    "def find_similar_songs(song_id, k):\n",
    "    song_index = song_features.index[song_features[\"song_id\"] == song_id].tolist()[0]\n",
    "\n",
    "    similarities = cosine_similarity(\n",
    "        song_features.drop(\"song_id\", axis=1).iloc[[song_index]],\n",
    "        song_features.drop(\"song_id\", axis=1),\n",
    "    )\n",
    "\n",
    "    similar_indices = similarities.argsort(axis=1)[:, : -k - 1 : -1]\n",
    "    similar_song_ids = [\n",
    "        song_features.iloc[i][\"song_id\"]\n",
    "        for i in similar_indices[0]\n",
    "        if song_features.iloc[i][\"song_id\"] != song_id\n",
    "    ]\n",
    "\n",
    "    similar_songs = [\n",
    "        (sim_song_id, rank + 1) for rank, sim_song_id in enumerate(similar_song_ids[:k])\n",
    "    ]\n",
    "    return similar_songs\n",
    "\n",
    "\n",
    "similar_songs_list = []\n",
    "for song_id in tqdm(song_ids, desc=\"Recommend songs using song similarity\"):\n",
    "    similar_songs = find_similar_songs(song_id, k=10)\n",
    "    for sim_song, rank in similar_songs:\n",
    "        similar_songs_list.append(\n",
    "            {\"source_song_id\": song_id, \"target_song_id\": sim_song, \"rank\": rank}\n",
    "        )\n",
    "\n",
    "similar_songs_df = pd.DataFrame(similar_songs_list)\n",
    "similar_songs_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
